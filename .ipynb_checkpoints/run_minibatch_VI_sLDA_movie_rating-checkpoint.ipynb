{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c064465-1463-42ba-80dc-5835fe1e6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from text_processing_utils import *\n",
    "import glob\n",
    "import datetime as dt\n",
    "import math\n",
    "from variational_inference_sLDA_M_step import *\n",
    "start_time = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d79fc90-8c61-4229-862f-33995aa21790",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ratings = np.array(pickle.load(open(\"data/scaledata/cleaned_ratings.pickle\", \"rb\")))\n",
    "cleaned_reviews = pickle.load(open(\"data/scaledata/cleaned_reviews.pickle\", \"rb\"))\n",
    "vocabulary_dict = pickle.load(open(\"data/scaledata/vocabulary_dict.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ddd8d24-7f82-4d25-b823-e790274b0c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 4506\n"
     ]
    }
   ],
   "source": [
    "# randomly split the movie reviews data into training/testing parts (80:20)\n",
    "np.random.seed(54321)\n",
    "train_indices = np.random.choice(np.arange(len(cleaned_ratings)), int(len(cleaned_ratings)*0.1), replace=False)\n",
    "test_indices = np.setdiff1d(np.arange(len(cleaned_ratings)), train_indices)\n",
    "print(len(train_indices), len(test_indices))\n",
    "train_bow = convert_bow([cleaned_reviews[i] for i in train_indices])\n",
    "test_bow = convert_bow([cleaned_reviews[i] for i in test_indices])\n",
    "train_y = cleaned_ratings[train_indices]\n",
    "test_y = cleaned_ratings[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40149f13-a0bc-4142-bed6-960add115585",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 12 # number of topics\n",
    "V = len(vocabulary_dict) # vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "561f59c7-95a9-450d-9604-9478ba22011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.81818182 -0.63636364 -0.45454545 -0.27272727 -0.09090909\n",
      "  0.09090909  0.27272727  0.45454545  0.63636364  0.81818182  1.        ]\n",
      "[0.31003397 0.38466031 0.46049951 0.42435579 0.66895848 0.82385343\n",
      " 0.55517983 0.71290784 0.5003519  0.73620155 0.67127189 0.78223165]\n",
      "[0.43759085 0.43685975 0.45601401 0.44761257 0.71268622 0.91113265\n",
      " 0.56679989 0.73485994 0.45278773 0.68957464 0.62365497 0.61290834]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\GitHub\\stat_6440_5430_final_project\\parallelized_sLDA_E_step.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m query_list \u001b[38;5;241m=\u001b[39m [(indx,) \u001b[38;5;241m+\u001b[39m q \u001b[38;5;28;01mfor\u001b[39;00m indx,q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(query_list)] \n\u001b[0;32m     24\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count())\n\u001b[1;32m---> 25\u001b[0m pool\u001b[38;5;241m.\u001b[39mmap(e_step_wrapper, query_list)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45895859 0.4306704  0.42090926 0.45069844 0.72746269 0.96979401\n",
      " 0.59261699 0.73306759 0.45643796 0.67794526 0.62905784 0.54293733]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/batch_VI_sLDA_movie_rating/Lambda.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m## save final results to Google Drive\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLambda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 42\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28meval\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mvar), \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/batch_VI_sLDA_movie_rating/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     43\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(elbo_vs_time, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/batch_VI_sLDA_movie_rating/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melbo_vs_time\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     44\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(time_elapsed, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/batch_VI_sLDA_movie_rating/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_elapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/batch_VI_sLDA_movie_rating/Lambda.pickle'"
     ]
    }
   ],
   "source": [
    "## initialization\n",
    "np.random.seed(12345)\n",
    "new_alpha = np.array([1/K]*K)\n",
    "new_xi = np.array([1/V]*V)\n",
    "new_eta = np.linspace(-1,1,K)\n",
    "new_delta = np.var(train_y, ddof=1)\n",
    "new_Lambda = np.abs(np.random.normal(loc=0, scale=0.1, size=K*V)).reshape((K,V)) # initialize Lambda randomly (add a small half-normal distribution to 1)\n",
    "input_data_x = train_bow\n",
    "input_data_y = train_y\n",
    "fpath = \"fragmented_output_files/\" # where to store the temporary fragmented files during parallelized E steps\n",
    "if not os.path.exists(fpath[:-1]):\n",
    "    os.makedirs(fpath[:-1])\n",
    "epsilon = 1e-4 # stopping criteria for convergence in E step\n",
    "\n",
    "## Run batch mode variational EM\n",
    "elbo_vs_time = [-math.inf]\n",
    "improve_in_elbo = math.inf\n",
    "time_elapsed = 0\n",
    "while improve_in_elbo > 0.01 and time_elapsed < 23.5 * 3600:\n",
    "    \n",
    "    ### Run one iteration of E step (parallelized)\n",
    "    %run -i \"parallelized_sLDA_E_step.py\"\n",
    "    all_gamma = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"gamma*\")]\n",
    "    new_gamma_dict = merge_dict(all_gamma)\n",
    "    new_gamma = create_gamma_matrix(new_gamma_dict)\n",
    "    all_phi = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"phi*\")]\n",
    "    new_phi = merge_dict(all_phi)\n",
    "    \n",
    "    ### Run one iteration of M step\n",
    "    m_step = batch_VI_sLDA_M_Step(K, train_bow, train_y,\n",
    "                                  new_alpha, new_xi, new_eta, new_delta, new_Lambda,\n",
    "                                  new_gamma, new_phi,\n",
    "                                  len(train_bow), 1e-4)\n",
    "    new_Lambda, new_alpha, new_xi, new_eta, new_delta, new_elbo = m_step.run()\n",
    "    improve_in_elbo = pct_diff(elbo_vs_time[-1], new_elbo)\n",
    "    elbo_vs_time.append(new_elbo)\n",
    "    current_time = dt.datetime.now()\n",
    "    time_elapsed = (current_time - start_time).seconds\n",
    "\n",
    "## save final results to Google Drive\n",
    "for var in ['Lambda', 'alpha', 'xi', 'eta', 'delta']:\n",
    "    pickle.dump(eval(\"new_\"+var), open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(var), \"wb\"))\n",
    "pickle.dump(elbo_vs_time, open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(\"elbo_vs_time\"), \"wb\"))\n",
    "pickle.dump(time_elapsed, open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(\"time_elapsed\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d5b0f-95b9-472c-a1bc-39f40f6d6f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
