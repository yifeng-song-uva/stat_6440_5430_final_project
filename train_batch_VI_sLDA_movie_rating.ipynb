{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Upload the 5 Python scripts (text_processing_utils.py, variational_inference_utils.py, variational_inference_sLDA_E_step.py, variational_inference_sLDA_M_step.py, parallelized_sLDA_E_step.py) to the same (temporary runtime) directory as this Google Colab notebook. Also, need to upload the movie reviews/rating data to my Google Drive Home Directory using the structure \"data/scaledata/xxx.pickle\"."
      ],
      "metadata": {
        "id": "GAOVT-HfaDR2"
      },
      "id": "GAOVT-HfaDR2"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cafda13b-fd3f-43c9-9acc-837f984263fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafda13b-fd3f-43c9-9acc-837f984263fe",
        "outputId": "25d2037e-0a8b-4550-e799-00db45a8a741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1c064465-1463-42ba-80dc-5835fe1e6c7d",
      "metadata": {
        "id": "1c064465-1463-42ba-80dc-5835fe1e6c7d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from text_processing_utils import *\n",
        "import glob\n",
        "import datetime as dt\n",
        "import math\n",
        "from variational_inference_sLDA_M_step import *\n",
        "start_time = dt.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8d79fc90-8c61-4229-862f-33995aa21790",
      "metadata": {
        "id": "8d79fc90-8c61-4229-862f-33995aa21790"
      },
      "outputs": [],
      "source": [
        "cleaned_ratings = np.array(pickle.load(open(\"/content/drive/MyDrive/data/scaledata/cleaned_ratings.pickle\", \"rb\")))\n",
        "cleaned_reviews = pickle.load(open(\"/content/drive/MyDrive/data/scaledata/cleaned_reviews.pickle\", \"rb\"))\n",
        "vocabulary_dict = pickle.load(open(\"/content/drive/MyDrive/data/scaledata/vocabulary_dict.pickle\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ddd8d24-7f82-4d25-b823-e790274b0c6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ddd8d24-7f82-4d25-b823-e790274b0c6b",
        "outputId": "ab209b9a-86c8-408e-cc70-9a03551eb5fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4004 1002\n"
          ]
        }
      ],
      "source": [
        "# randomly split the movie reviews data into training/testing parts (80:20)\n",
        "np.random.seed(54321)\n",
        "train_indices = np.random.choice(np.arange(len(cleaned_ratings)), int(len(cleaned_ratings)*0.8), replace=False)\n",
        "test_indices = np.setdiff1d(np.arange(len(cleaned_ratings)), train_indices)\n",
        "print(len(train_indices), len(test_indices))\n",
        "train_bow = convert_bow([cleaned_reviews[i] for i in train_indices])\n",
        "test_bow = convert_bow([cleaned_reviews[i] for i in test_indices])\n",
        "train_y = cleaned_ratings[train_indices]\n",
        "test_y = cleaned_ratings[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40149f13-a0bc-4142-bed6-960add115585",
      "metadata": {
        "id": "40149f13-a0bc-4142-bed6-960add115585"
      },
      "outputs": [],
      "source": [
        "K = 12 # number of topics\n",
        "V = len(vocabulary_dict) # vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "561f59c7-95a9-450d-9604-9478ba22011e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "561f59c7-95a9-450d-9604-9478ba22011e",
        "outputId": "d5fef213-8a40-4d52-a2f3-8d5660c593ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variational EM iteration 1: elbo = -5908122.871837378\n",
            "variational EM iteration 2: elbo = -5630797.479478836\n",
            "variational EM iteration 3: elbo = -5535514.019721031\n",
            "variational EM iteration 4: elbo = -5485360.767313361\n",
            "variational EM iteration 5: elbo = -5452580.504116774\n",
            "variational EM iteration 6: elbo = -5428502.491692662\n",
            "variational EM iteration 7: elbo = -5409659.490482688\n",
            "variational EM iteration 8: elbo = -5394283.701215148\n",
            "variational EM iteration 9: elbo = -5381420.426229715\n",
            "variational EM iteration 10: elbo = -5370430.354780674\n",
            "variational EM iteration 11: elbo = -5360796.517108142\n",
            "variational EM iteration 12: elbo = -5352409.469674647\n",
            "variational EM iteration 13: elbo = -5345080.30678916\n",
            "variational EM iteration 14: elbo = -5338489.6775407195\n",
            "variational EM iteration 15: elbo = -5332661.142350972\n",
            "variational EM iteration 16: elbo = -5327512.476150274\n",
            "variational EM iteration 17: elbo = -5322884.21004504\n",
            "variational EM iteration 18: elbo = -5318650.788538456\n",
            "variational EM iteration 19: elbo = -5314850.211072922\n",
            "variational EM iteration 20: elbo = -5311420.014578134\n",
            "variational EM iteration 21: elbo = -5308265.7018199265\n",
            "variational EM iteration 22: elbo = -5305380.228910357\n",
            "variational EM iteration 23: elbo = -5302814.621008724\n",
            "variational EM iteration 24: elbo = -5300378.291080534\n",
            "variational EM iteration 25: elbo = -5298135.301126659\n",
            "variational EM iteration 26: elbo = -5296086.932679996\n",
            "variational EM iteration 27: elbo = -5294164.164268836\n",
            "variational EM iteration 28: elbo = -5292376.989645153\n",
            "variational EM iteration 29: elbo = -5290695.658377364\n",
            "variational EM iteration 30: elbo = -5289101.855162427\n",
            "variational EM iteration 31: elbo = -5287591.527391106\n",
            "variational EM iteration 32: elbo = -5286184.760211676\n",
            "variational EM iteration 33: elbo = -5284859.827907383\n",
            "variational EM iteration 34: elbo = -5283607.23338154\n",
            "variational EM iteration 35: elbo = -5282411.679636978\n",
            "variational EM iteration 36: elbo = -5281272.2465810925\n",
            "variational EM iteration 37: elbo = -5280163.112383597\n",
            "variational EM iteration 38: elbo = -5279090.907431498\n",
            "variational EM iteration 39: elbo = -5278086.760962121\n"
          ]
        }
      ],
      "source": [
        "## initialization\n",
        "np.random.seed(12345)\n",
        "new_alpha = np.array([1/K]*K)\n",
        "new_xi = np.array([1/V]*V)\n",
        "new_eta = np.linspace(-1,1,K)\n",
        "new_delta = np.var(train_y, ddof=1)\n",
        "new_Lambda = np.abs(np.random.normal(loc=0, scale=0.1, size=K*V)).reshape((K,V)) # initialize Lambda randomly (add a small half-normal distribution to 1)\n",
        "input_data_x = train_bow\n",
        "input_data_y = train_y\n",
        "fpath = \"fragmented_output_files/\" # where to store the temporary fragmented files during parallelized E steps\n",
        "if not os.path.exists(fpath[:-1]):\n",
        "    os.makedirs(fpath[:-1])\n",
        "epsilon = 1e-4 # stopping criteria for convergence in E step\n",
        "\n",
        "## Run batch mode variational EM\n",
        "elbo_vs_time = [-math.inf]\n",
        "improve_in_elbo = math.inf\n",
        "time_elapsed = 0\n",
        "j = 0\n",
        "while improve_in_elbo > 0.01 and time_elapsed < 23.5 * 3600: # there's a time limit to the Google Colab Pro+\n",
        "\n",
        "    ### Run one iteration of E step (parallelized)\n",
        "    %run -i \"parallelized_sLDA_E_step.py\"\n",
        "    all_gamma = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"gamma*\")]\n",
        "    new_gamma_dict = merge_dict(all_gamma)\n",
        "    new_gamma = create_gamma_matrix(new_gamma_dict)\n",
        "    all_phi = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"phi*\")]\n",
        "    new_phi = merge_dict(all_phi)\n",
        "\n",
        "    ### Run one iteration of M step\n",
        "    m_step = batch_VI_sLDA_M_Step(K, train_bow, train_y,\n",
        "                                  new_alpha, new_xi, new_eta, new_delta, new_Lambda,\n",
        "                                  new_gamma, new_phi,\n",
        "                                  len(train_bow), 1e-4)\n",
        "    new_Lambda, new_alpha, new_xi, new_eta, new_delta, new_elbo = m_step.run()\n",
        "    improve_in_elbo = pct_diff(elbo_vs_time[-1], new_elbo)\n",
        "    elbo_vs_time.append(new_elbo)\n",
        "    current_time = dt.datetime.now()\n",
        "    time_elapsed = (current_time - start_time).seconds\n",
        "    j += 1\n",
        "    print(\"variational EM iteration {}: elbo =\".format(j), new_elbo)\n",
        "\n",
        "## save final results to Google Drive\n",
        "for var in ['Lambda', 'alpha', 'xi', 'eta', 'delta']:\n",
        "    pickle.dump(eval(\"new_\"+var), open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(var), \"wb\"))\n",
        "pickle.dump(elbo_vs_time, open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(\"elbo_vs_time\"), \"wb\"))\n",
        "pickle.dump(time_elapsed, open(\"/content/drive/MyDrive/batch_VI_sLDA_movie_rating/{}.pickle\".format(\"time_elapsed\"), \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45d5b0f-95b9-472c-a1bc-39f40f6d6f31",
      "metadata": {
        "id": "c45d5b0f-95b9-472c-a1bc-39f40f6d6f31"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}