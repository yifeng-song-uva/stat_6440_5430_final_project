{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "GAOVT-HfaDR2",
      "metadata": {
        "id": "GAOVT-HfaDR2"
      },
      "source": [
        "Upload the 5 Python scripts (text_processing_utils.py, variational_inference_utils.py, variational_inference_sLDA_E_step.py, variational_inference_sLDA_M_step_diagnostics.py, parallelized_sLDA_E_step.py) to the same (temporary runtime) directory as this Google Colab notebook. Also, need to upload the movie reviews/rating data to my Google Drive Home Directory using the structure \"data/scaledata/xxx.pickle\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafda13b-fd3f-43c9-9acc-837f984263fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafda13b-fd3f-43c9-9acc-837f984263fe",
        "outputId": "edc353d6-8cb6-4e61-f53f-9d0d7686b844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c064465-1463-42ba-80dc-5835fe1e6c7d",
      "metadata": {
        "id": "1c064465-1463-42ba-80dc-5835fe1e6c7d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from text_processing_utils import *\n",
        "from variational_inference_utils import *\n",
        "import glob\n",
        "import datetime as dt\n",
        "import math\n",
        "from variational_inference_sLDA_M_step_diagnostics import *\n",
        "start_time = dt.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d79fc90-8c61-4229-862f-33995aa21790",
      "metadata": {
        "id": "8d79fc90-8c61-4229-862f-33995aa21790"
      },
      "outputs": [],
      "source": [
        "cleaned_ratings = np.array(pickle.load(open(\"/content/drive/MyDrive/data/scaledata/cleaned_ratings.pickle\", \"rb\")))\n",
        "cleaned_reviews = pickle.load(open(\"/content/drive/MyDrive/data/scaledata/cleaned_reviews.pickle\", \"rb\"))\n",
        "vocabulary_dict = pickle.load(open(\"/content/drive/MyDrive/data/scaledata/vocabulary_dict.pickle\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ddd8d24-7f82-4d25-b823-e790274b0c6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ddd8d24-7f82-4d25-b823-e790274b0c6b",
        "outputId": "e5c28b49-b801-4c8d-aef0-5da6b292222b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4004 1002\n"
          ]
        }
      ],
      "source": [
        "# randomly split the movie reviews data into training/testing parts (80:20)\n",
        "np.random.seed(54321)\n",
        "train_indices = np.random.choice(np.arange(len(cleaned_ratings)), int(len(cleaned_ratings)*0.8), replace=False)\n",
        "test_indices = np.setdiff1d(np.arange(len(cleaned_ratings)), train_indices)\n",
        "print(len(train_indices), len(test_indices))\n",
        "train_bow = convert_bow([cleaned_reviews[i] for i in train_indices])\n",
        "test_bow = convert_bow([cleaned_reviews[i] for i in test_indices])\n",
        "train_y = cleaned_ratings[train_indices]\n",
        "test_y = cleaned_ratings[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40149f13-a0bc-4142-bed6-960add115585",
      "metadata": {
        "id": "40149f13-a0bc-4142-bed6-960add115585"
      },
      "outputs": [],
      "source": [
        "K = 24 # number of topics\n",
        "V = len(vocabulary_dict) # vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "561f59c7-95a9-450d-9604-9478ba22011e",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "561f59c7-95a9-450d-9604-9478ba22011e",
        "outputId": "22586e6a-07e9-4ba8-825c-b93842e9db4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "variational EM iteration 1: elbo = -6510467.106228828\n",
            "variational EM iteration 2: elbo = -5941919.5423913\n",
            "variational EM iteration 3: elbo = -5752617.271614552\n",
            "variational EM iteration 4: elbo = -5649529.694185734\n",
            "variational EM iteration 5: elbo = -5578971.701344013\n",
            "variational EM iteration 6: elbo = -5528988.384536505\n",
            "variational EM iteration 7: elbo = -5492006.223221302\n",
            "variational EM iteration 8: elbo = -5463784.743897438\n",
            "variational EM iteration 9: elbo = -5440988.5430448055\n",
            "variational EM iteration 10: elbo = -5422175.445895195\n",
            "variational EM iteration 11: elbo = -5406227.3154325485\n",
            "variational EM iteration 12: elbo = -5392597.401759386\n",
            "variational EM iteration 13: elbo = -5380857.512611151\n",
            "variational EM iteration 14: elbo = -5370658.785284996\n",
            "variational EM iteration 15: elbo = -5361605.147365332\n",
            "variational EM iteration 16: elbo = -5353685.737860322\n",
            "variational EM iteration 17: elbo = -5346712.803583741\n",
            "variational EM iteration 18: elbo = -5340300.49368763\n",
            "variational EM iteration 19: elbo = -5334699.770859361\n",
            "variational EM iteration 20: elbo = -5329704.049281001\n",
            "variational EM iteration 21: elbo = -5325201.209599972\n",
            "variational EM iteration 22: elbo = -5321152.347719908\n",
            "variational EM iteration 23: elbo = -5317421.532597065\n",
            "variational EM iteration 24: elbo = -5313966.72561574\n",
            "variational EM iteration 25: elbo = -5310806.268056631\n",
            "variational EM iteration 26: elbo = -5307883.036954761\n",
            "variational EM iteration 27: elbo = -5305181.093202114\n",
            "variational EM iteration 28: elbo = -5302785.559204578\n",
            "variational EM iteration 29: elbo = -5300551.879138231\n",
            "variational EM iteration 30: elbo = -5298412.788700342\n",
            "variational EM iteration 31: elbo = -5296440.524388075\n",
            "variational EM iteration 32: elbo = -5294589.23571676\n",
            "variational EM iteration 33: elbo = -5292886.856403708\n",
            "variational EM iteration 34: elbo = -5291248.97098583\n",
            "variational EM iteration 35: elbo = -5289676.25177896\n",
            "variational EM iteration 36: elbo = -5288188.626092732\n",
            "variational EM iteration 37: elbo = -5286789.475769997\n",
            "variational EM iteration 38: elbo = -5285511.83235687\n",
            "variational EM iteration 39: elbo = -5284312.327323496\n",
            "variational EM iteration 40: elbo = -5283142.780663729\n",
            "variational EM iteration 41: elbo = -5282017.352120757\n",
            "variational EM iteration 42: elbo = -5280928.602482915\n",
            "variational EM iteration 43: elbo = -5279888.031290829\n",
            "variational EM iteration 44: elbo = -5278922.786993861\n",
            "variational EM iteration 45: elbo = -5277992.460260749\n",
            "variational EM iteration 46: elbo = -5277094.124003351\n",
            "variational EM iteration 47: elbo = -5276238.3990597725\n",
            "variational EM iteration 48: elbo = -5275402.943592906\n",
            "variational EM iteration 49: elbo = -5274614.965828061\n",
            "variational EM iteration 50: elbo = -5273867.979429126\n",
            "variational EM iteration 51: elbo = -5273135.1296363175\n",
            "variational EM iteration 52: elbo = -5272431.5035788715\n",
            "variational EM iteration 53: elbo = -5271756.762131214\n",
            "variational EM iteration 54: elbo = -5271110.317230523\n",
            "variational EM iteration 55: elbo = -5270498.002924532\n",
            "variational EM iteration 56: elbo = -5269894.736503392\n",
            "variational EM iteration 57: elbo = -5269302.572557002\n",
            "variational EM iteration 58: elbo = -5268727.738041669\n",
            "variational EM iteration 59: elbo = -5268184.583358318\n",
            "variational EM iteration 60: elbo = -5267643.23604998\n",
            "variational EM iteration 61: elbo = -5267108.475595176\n",
            "variational EM iteration 62: elbo = -5266601.471600771\n"
          ]
        }
      ],
      "source": [
        "## initialization\n",
        "np.random.seed(12345)\n",
        "new_alpha = np.array([1/K]*K)\n",
        "new_xi = np.array([1/V]*V)\n",
        "new_eta = np.linspace(-1,1,K)\n",
        "new_delta = np.var(train_y, ddof=1)\n",
        "new_Lambda = np.abs(np.random.normal(loc=0, scale=0.1, size=K*V)).reshape((K,V)) # initialize Lambda randomly (add a small half-normal distribution to 1)\n",
        "input_data_x = train_bow\n",
        "input_data_y = train_y\n",
        "fpath = \"fragmented_output_files_0/\" # where to store the temporary fragmented files during parallelized E steps\n",
        "if not os.path.exists(fpath[:-1]):\n",
        "    os.makedirs(fpath[:-1])\n",
        "else:\n",
        "    delete_all_files(fpath[:-1])\n",
        "epsilon = 1e-4 # stopping criteria for convergence of local parameters in E step and for convergence of alpha and xi in M step\n",
        "predict = False\n",
        "## Run batch mode variational EM\n",
        "elbo_vs_time = [-math.inf]\n",
        "improve_in_elbo = math.inf\n",
        "time_elapsed = 0\n",
        "j = 0\n",
        "while improve_in_elbo > 0.01 and time_elapsed < 23.5 * 3600: # there's a time limit to the Google Colab Pro+\n",
        "\n",
        "    ### Run one iteration of E step (parallelized)\n",
        "    %run -i \"parallelized_sLDA_E_step.py\"\n",
        "    all_gamma = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"gamma*\")]\n",
        "    new_gamma_dict = merge_dict(all_gamma)\n",
        "    new_gamma = create_gamma_matrix(new_gamma_dict)\n",
        "    all_phi = [pickle.load(open(fn, \"rb\")) for fn in glob.glob(fpath + \"phi*\")]\n",
        "    new_phi = merge_dict(all_phi)\n",
        "\n",
        "    ### Run one iteration of M step\n",
        "    m_step = batch_VI_sLDA_M_Step(K, train_bow, train_y,\n",
        "                                  new_alpha, new_xi, new_eta, new_delta, new_Lambda,\n",
        "                                  new_gamma, new_phi,\n",
        "                                  len(train_bow), 1e-5)\n",
        "    new_Lambda, new_alpha, new_xi, new_eta, new_delta, new_elbo = m_step.run()\n",
        "    improve_in_elbo = pct_diff(elbo_vs_time[-1], new_elbo)\n",
        "    elbo_vs_time.append(new_elbo)\n",
        "    current_time = dt.datetime.now()\n",
        "    time_elapsed = (current_time - start_time).seconds\n",
        "    j += 1\n",
        "    print(\"variational EM iteration {}: elbo =\".format(j), new_elbo)\n",
        "\n",
        "## save final results to Google Drive\n",
        "output_dir = \"/content/drive/MyDrive/data/scaledata/diagnostic_0\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "for var in ['Lambda', 'alpha', 'xi', 'eta', 'delta']:\n",
        "    pickle.dump(eval(\"new_\"+var), open(output_dir + \"/{}.pickle\".format(var), \"wb\"))\n",
        "pickle.dump(elbo_vs_time, open(output_dir + \"/{}.pickle\".format(\"elbo_vs_time\"), \"wb\"))\n",
        "pickle.dump(time_elapsed, open(output_dir + \"/{}.pickle\".format(\"time_elapsed\"), \"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}